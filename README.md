# Advancing Visual Grounding with Scene Knowledge: Benchmark and Method (SK-VG)

We introduce a challenging task that requires VG models to reason over **(image, scene knowledge, query)** triples and build a new dataset named SK-VG on top of real images through manual annotations.
In SK-VG, the image content and referring expressions  are not sufficient to ground the target objects, forcing the models to have a reasoning ability on the long-form scene  knowledge.

![image](assets/animation.gif)

# Data

You can download the dataset from [Google Drive](https://drive.google.com/file/d/1XShB2JK0WDG_KDRE2obCHuAjkoCmTo4f/view?usp=sharing).

# Citation
If you find this dataset helpful, please cite the paper below.

```angular2html
@inproceedings{chen2023advancing,
        title={Advancing Visual Grounding With Scene Knowledge: Benchmark and Method},
        author={Chen, Zhihong and Zhang, Ruifei and Song, Yibing and Wan, Xiang and Li, Guanbin},
        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
        pages={15039--15049},
        year={2023}
}
```